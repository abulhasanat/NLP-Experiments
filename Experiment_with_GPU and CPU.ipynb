{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix multiplication with pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abulhasanat/NLP-Experiments/blob/master/Experiment_with_GPU%20and%20CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gjyd7qUjyic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA1s2xyxIpv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "664f134b-cc56-4de9-ea3d-5c5e52aff265"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvu3U6OkRGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "08f963fd-66b1-42d8-9b02-0801a90ee2db"
      },
      "source": [
        "%%time\n",
        "a = np.random.randn(1000,1000)\n",
        "result = np.matmul(a,a)\n",
        "del a, result"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 138 ms, sys: 14.5 ms, total: 152 ms\n",
            "Wall time: 115 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWMJ_h6EklKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b028ace3-6bde-4fdc-92a5-3e9140f7d264"
      },
      "source": [
        "%%time\n",
        "z = torch.randn(1000,1000)\n",
        "result = torch.matmul(z,z)\n",
        "del z, result"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 40.5 ms, sys: 950 µs, total: 41.5 ms\n",
            "Wall time: 91.1 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1KEnA4lkiOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b40a628f-0c5f-4098-ed03-dd04b9687743"
      },
      "source": [
        "%%time\n",
        "b = np.random.randn(10000,10000)\n",
        "result = np.matmul(b,b)\n",
        "del b, result"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 43s, sys: 681 ms, total: 1min 44s\n",
            "Wall time: 55.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_b7A6w6kmg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4bad2496-d202-453f-f8a5-7530124c6a36"
      },
      "source": [
        "%%time\n",
        "y = torch.randn(10000,10000)\n",
        "result = torch.matmul(y,y)\n",
        "del y, result"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 25.2 s, sys: 204 µs, total: 25.2 s\n",
            "Wall time: 25.2 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4kLY8kZkuMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ce29dc59-09ca-4650-a6c4-dfeea4064fd9"
      },
      "source": [
        "%%time\n",
        "x = torch.randn(10000,10000).cuda()\n",
        "result = torch.matmul(x,x)\n",
        "del x, result"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.01 s, sys: 1.01 ms, total: 1.01 s\n",
            "Wall time: 1.01 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgY0Xo8dkvtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e376ffd-4c76-4ef5-acc1-5abec85083fa"
      },
      "source": [
        "%%time\n",
        "w = torch.randn(10000,10000).cuda()\n",
        "result = torch.matmul(w,w)\n",
        "del w, result\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.03 s, sys: 0 ns, total: 1.03 s\n",
            "Wall time: 1.03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOzxnj_xQMSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "86968350-2f5c-4ae8-8ed9-cf42110076e2"
      },
      "source": [
        "%%time\n",
        "v = torch.randn(20000,20000).cuda()\n",
        "result = torch.matmul(v,v)\n",
        "del v, result\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.12 s, sys: 650 ms, total: 3.77 s\n",
            "Wall time: 3.77 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbjA6P9xQuaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "01cbf56f-dc59-4b0e-d0c1-5ab026c024f3"
      },
      "source": [
        "%%time\n",
        "v = torch.randn(30000,30000).cuda()\n",
        "result = torch.matmul(v,v)\n",
        "del v, result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 7.2 s, sys: 1.38 s, total: 8.58 s\n",
            "Wall time: 8.6 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYE9tAuHRuKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "5ed6ec9d-2560-4147-f027-6bb2c17eba4e"
      },
      "source": [
        "%%time\n",
        "v = torch.randn(40000,40000).cuda()\n",
        "result = torch.matmul(v,v)\n",
        "del v, result"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 12.8 s, sys: 2.65 s, total: 15.5 s\n",
            "Wall time: 15.9 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE1zT5XxRyh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a615cc6f-bddc-43de-b402-6c8fece4efff"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1t8dRKdTGMFg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "7a45f335-3e29-403a-aeb8-6aa7e527e5d3"
      },
      "source": [
        "g1 = tf.random.Generator.from_seed(1)\n",
        "print(g1.normal(shape=[200, 30]))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[[ 0.43842274 -0.53439844 -0.07710262 ... -0.08857017  0.69211644\n",
            "   0.84215707]\n",
            " [-0.06378496  0.92800784 -0.6039789  ... -0.5445254   1.5222508\n",
            "   0.59303206]\n",
            " [-0.63509274  0.37035653 -1.0939722  ...  0.85445154  0.1175475\n",
            "   0.03493892]\n",
            " ...\n",
            " [ 0.09231739 -0.35167617 -0.7733934  ...  1.1000215   2.6729069\n",
            "   1.5629487 ]\n",
            " [-0.35880488  1.0019118   0.59992516 ... -0.6157689  -0.1618813\n",
            "   0.8175728 ]\n",
            " [-0.74993825  0.5005443   1.2893976  ...  0.14361963 -0.4893485\n",
            "  -0.53376347]], shape=(200, 30), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMlFYFHVBxDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b9313511-0c85-4e39-f4b4-5ea3c93180df"
      },
      "source": [
        "%%time\n",
        "g1 = tf.random.Generator.from_seed(1)\n",
        "v=g1.normal(shape=[10000, 10000])\n",
        "# v=tf.random(1000,1000)\n",
        "result=tf.matmul(v,v)\n",
        "del v,result"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.7 ms, sys: 0 ns, total: 2.7 ms\n",
            "Wall time: 2.64 ms\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}