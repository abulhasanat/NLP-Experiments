{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix multiplication with pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abulhasanat/NLP-Experiments/blob/master/Experiment_with_GPU%20and%20CPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Gjyd7qUjyic",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import torch"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WA1s2xyxIpv2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "76e008e5-9f30-4967-8312-0ad32f782712"
      },
      "source": [
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fO7L7HE-O0Tl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1c7d01da-f9e2-40f5-bd2b-f075d2e6ff19"
      },
      "source": [
        "device =torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "device"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qvu3U6OkRGu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "935ce78c-4882-49a7-deca-5979b70fd269"
      },
      "source": [
        "%%time\n",
        "a = np.random.randn(1000,1000)\n",
        "result = np.matmul(a,a)\n",
        "del a, result"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 146 ms, sys: 10.3 ms, total: 156 ms\n",
            "Wall time: 107 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AWMJ_h6EklKl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "e9131e02-65d1-47a9-c941-451da1921ad8"
      },
      "source": [
        "%%time\n",
        "z = torch.randn(1000,1000)\n",
        "result = torch.matmul(z,z)\n",
        "del z, result"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 37.8 ms, sys: 223 µs, total: 38 ms\n",
            "Wall time: 89.8 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1KEnA4lkiOk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "504c029c-b24d-4229-d7df-e4817a4895db"
      },
      "source": [
        "%%time\n",
        "b = np.random.randn(10000,10000)\n",
        "result = np.matmul(b,b)\n",
        "del b, result"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1min 37s, sys: 555 ms, total: 1min 37s\n",
            "Wall time: 51.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g_b7A6w6kmg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2e200247-cb5b-40ab-a8b6-e0c1af2d9320"
      },
      "source": [
        "%%time\n",
        "y = torch.randn(10000,10000)\n",
        "result = torch.matmul(y,y)\n",
        "del y, result"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 23.4 s, sys: 349 µs, total: 23.4 s\n",
            "Wall time: 23.4 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlNyankCO6PY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "2edd8686-49fa-45bf-fd30-ef2eeebf50d7"
      },
      "source": [
        "%%time\n",
        "x = torch.randn(10000,10000).to(device)\n",
        "result = torch.matmul(x,x)\n",
        "del x, result"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.02 s, sys: 2 ms, total: 1.02 s\n",
            "Wall time: 1.03 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i4kLY8kZkuMh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1807b1ea-8e3f-434e-97f3-a3c1c333723e"
      },
      "source": [
        "%%time\n",
        "x = torch.randn(10000,10000).cuda()\n",
        "result = torch.matmul(x,x)\n",
        "del x, result"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 1.02 s, sys: 1.91 ms, total: 1.02 s\n",
            "Wall time: 1.02 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgY0Xo8dkvtS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9792c5b8-7c1a-401f-828c-bfd1fa56d4b7"
      },
      "source": [
        "%%time\n",
        "w = torch.randn(10000,10000).cuda()\n",
        "result = torch.matmul(w,w)\n",
        "del w, result\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 998 ms, sys: 155 ms, total: 1.15 s\n",
            "Wall time: 1.15 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OOzxnj_xQMSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "1fd4babf-38f3-441e-a0d3-9dd633bd3b6d"
      },
      "source": [
        "%%time\n",
        "v = torch.randn(20000,20000).cuda()\n",
        "result = torch.matmul(v,v)\n",
        "del v, result\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.91 s, sys: 511 ms, total: 4.42 s\n",
            "Wall time: 4.42 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbjA6P9xQuaW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "0d9104f8-6967-46e3-8c1a-fd1b45f8205f"
      },
      "source": [
        "%%time\n",
        "v = torch.randn(30000,30000).cuda()\n",
        "result = torch.matmul(v,v)\n",
        "del v, result"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 8.69 s, sys: 806 ms, total: 9.5 s\n",
            "Wall time: 9.5 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYE9tAuHRuKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "68e15a46-8b42-471f-c471-89b9efd66369"
      },
      "source": [
        "%%time\n",
        "v = torch.randn(40000,40000).cuda()\n",
        "result = torch.matmul(v,v)\n",
        "del v, result"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 16 s, sys: 2.46 s, total: 18.5 s\n",
            "Wall time: 18.8 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE1zT5XxRyh3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b81059d0-8c3f-4ebc-9a8f-71b62971c61b"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Get the GPU device name.\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "# The device name should look like the following:\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yMlFYFHVBxDx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "498e854b-0599-41c0-9a15-5dd7aa30c018"
      },
      "source": [
        "%%time\n",
        "g1 = tf.random.Generator.from_seed(1)\n",
        "v=g1.normal(shape=[10000, 10000])\n",
        "# v=tf.random(1000,1000)\n",
        "result=tf.matmul(v,v)\n",
        "del v,result"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.93 ms, sys: 0 ns, total: 2.93 ms\n",
            "Wall time: 4.53 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M45Q-GbhLPzc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9512eaf0-e9b7-4016-9c31-25e5c52b0fb2"
      },
      "source": [
        "%%time\n",
        "with tf.device('/gpu:0'):\n",
        "  g1 = tf.random.Generator.from_seed(1)\n",
        "  v=g1.normal(shape=[10000, 10000])\n",
        "  # v=tf.random(1000,1000)\n",
        "  result=tf.matmul(v,v)\n",
        "  del v,result"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 3.14 ms, sys: 5 µs, total: 3.15 ms\n",
            "Wall time: 2.93 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c4ZhKY0gMuFx",
        "colab_type": "text"
      },
      "source": [
        "Based on the above two execution times, we can conclude that Tensorflow uses GPU by default.\n",
        "\n",
        "Lets see the execution time with forcefully allocating the CPU device.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDWPLgXcMRfm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "eefacabf-06b7-4f9b-a670-c59e97be8caa"
      },
      "source": [
        "%%time\n",
        "with tf.device('/cpu:0'):\n",
        "  g1 = tf.random.Generator.from_seed(1)\n",
        "  v=g1.normal(shape=[10000, 10000])\n",
        "  # v=tf.random(1000,1000)\n",
        "  result=tf.matmul(v,v)\n",
        "  del v,result"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 54.9 s, sys: 57.6 ms, total: 55 s\n",
            "Wall time: 28 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JX8YrEpbNJUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}