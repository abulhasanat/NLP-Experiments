{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-generation-lstm(tf).ipynb",
      "provenance": [],
      "mount_file_id": "1RU6eywV55rizlQrk8p6zbE1Y562jOyaK",
      "authorship_tag": "ABX9TyOr8tmMFi/200YSiLoWJdFi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abulhasanat/NLP-Experiments/blob/master/text_generation_lstm(tf).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIJJzj-cj9Eb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0B58JtzfBZ5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bf7bb48f-eb2f-41fb-e9b6-1b0bb8b68e32"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout\n",
        "from string import punctuation\n",
        "import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOBClf5RfJH1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3cb33e8c-fcef-4f46-a1e8-3c66471c4ebb"
      },
      "source": [
        "import requests\n",
        "\n",
        "if not os.path.isdir(\"data\"):\n",
        "    os.mkdir(\"data\")\n",
        "\n",
        "content = requests.get(\"http://www.gutenberg.org/cache/epub/11/pg11.txt\").text\n",
        "open(\"data/wonderland.txt\", \"w\", encoding=\"utf-8\").write(content)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "167516"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHhvdiTgfWdL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sequence_length = 100\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 30\n",
        "# dataset file path\n",
        "FILE_PATH = \"data/wonderland.txt\"\n",
        "BASENAME = os.path.basename(FILE_PATH)\n",
        "# read the data\n",
        "text = open(FILE_PATH, encoding=\"utf-8\").read()\n",
        "# remove caps, comment this code if you want uppercase characters as well\n",
        "text = text.lower()\n",
        "# remove punctuation\n",
        "text = text.translate(str.maketrans(\"\", \"\", punctuation))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1_gijHaZfcej",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "4a379de4-9df1-4e14-cde5-323f1370bada"
      },
      "source": [
        "# print some stats\n",
        "n_chars = len(text)\n",
        "vocab = ''.join(sorted(set(text)))\n",
        "print(\"unique_chars:\", vocab)\n",
        "n_unique_chars = len(vocab)\n",
        "print(\"Number of characters:\", n_chars)\n",
        "print(\"Number of unique characters:\", n_unique_chars)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unique_chars: \n",
            " 0123456789abcdefghijklmnopqrstuvwxyz﻿\n",
            "Number of characters: 154861\n",
            "Number of unique characters: 39\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8Uz1wTwfiSb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# dictionary that converts characters to integers\n",
        "unique_chars=vocab\n",
        "char2int = {c: i for i, c in enumerate(unique_chars)}\n",
        "# dictionary that converts integers to characters\n",
        "int2char = {i: c for i, c in enumerate(unique_chars)}"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAPOa7VifnAz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save these dictionaries for later generation\n",
        "pickle.dump(char2int, open(f\"{BASENAME}-char2int.pickle\", \"wb\"))\n",
        "pickle.dump(int2char, open(f\"{BASENAME}-int2char.pickle\", \"wb\"))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUiqhFFagSCz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# convert all text into integers\n",
        "encoded_text = np.array([char2int[c] for c in text])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MzB39wAbgVpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# construct tf.data.Dataset object\n",
        "char_dataset = tf.data.Dataset.from_tensor_slices(encoded_text)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxmIKxXpggn7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "684d92a7-1ee3-43c4-dd74-5b0027e2819e"
      },
      "source": [
        "# print first 5 characters\n",
        "for char in char_dataset.take(8):\n",
        "    print(char.numpy(), int2char[char.numpy()])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "38 ﻿\n",
            "27 p\n",
            "29 r\n",
            "26 o\n",
            "21 j\n",
            "16 e\n",
            "14 c\n",
            "31 t\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPgiPEJZgtjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "68be094d-5be0-4ffb-bbc9-e26bff84f036"
      },
      "source": [
        "# build sequences by batching\n",
        "sequences = char_dataset.batch(2*sequence_length + 1, drop_remainder=True)\n",
        "\n",
        "# print sequences\n",
        "for sequence in sequences.take(2):\n",
        "    print(''.join([int2char[i] for i in sequence.numpy()]))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "﻿project gutenbergs alices adventures in wonderland by lewis carroll\n",
            "\n",
            "this ebook is for the use of anyone anywhere at no cost and with\n",
            "almost no restrictions whatsoever  you may copy it give it away or\n",
            "\n",
            "reuse it under the terms of the project gutenberg license included\n",
            "with this ebook or online at wwwgutenbergorg\n",
            "\n",
            "\n",
            "title alices adventures in wonderland\n",
            "\n",
            "author lewis carroll\n",
            "\n",
            "posting date june 25 2008\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6bcY-LLguGT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_sample(sample):\n",
        "    ds = tf.data.Dataset.from_tensors((sample[:sequence_length], sample[sequence_length]))\n",
        "    for i in range(1, (len(sample)-1) // 2):\n",
        "        input_ = sample[i: i+sequence_length]\n",
        "        target = sample[i+sequence_length]\n",
        "        # extend the dataset with these samples by concatenate() method\n",
        "        other_ds = tf.data.Dataset.from_tensors((input_, target))\n",
        "        ds = ds.concatenate(other_ds)\n",
        "    return ds\n",
        "\n",
        "# prepare inputs and targets\n",
        "dataset = sequences.flat_map(split_sample)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlSWTZwig4Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_samples(input_, target):\n",
        "    # onehot encode the inputs and the targets\n",
        "    return tf.one_hot(input_, n_unique_chars), tf.one_hot(target, n_unique_chars)\n",
        "\n",
        "\n",
        "dataset = dataset.map(one_hot_samples)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3681InJjg78j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "1702e7c7-9dfd-48d1-a9a6-af598d08dbbb"
      },
      "source": [
        "# print first 2 samples\n",
        "for element in dataset.take(2):\n",
        "    print(\"Input:\", ''.join([int2char[np.argmax(char_vector)] for char_vector in element[0].numpy()]))\n",
        "    print(\"Target:\", int2char[np.argmax(element[1].numpy())])\n",
        "    print(\"Input shape:\", element[0].shape)\n",
        "    print(\"Target shape:\", element[1].shape)\n",
        "    print(\"=\"*50, \"\\n\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input: ﻿project gutenbergs alices adventures in wonderland by lewis carroll\n",
            "\n",
            "this ebook is for the use of a\n",
            "Target: n\n",
            "Input shape: (100, 39)\n",
            "Target shape: (39,)\n",
            "================================================== \n",
            "\n",
            "Input: project gutenbergs alices adventures in wonderland by lewis carroll\n",
            "\n",
            "this ebook is for the use of an\n",
            "Target: y\n",
            "Input shape: (100, 39)\n",
            "Target shape: (39,)\n",
            "================================================== \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWsFinKxhAuj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# repeat, shuffle and batch the dataset\n",
        "ds = dataset.repeat().shuffle(1024).batch(BATCH_SIZE, drop_remainder=True)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BYjxdEn5hG_T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, n_unique_chars), return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(256),\n",
        "    Dense(n_unique_chars, activation=\"softmax\"),\n",
        "])"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9bZoxzNhgPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.optimizers.RMSprop(lr=0.01)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zc-fhBYxhKCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1b420af5-7c2f-4289-8a76-cafd08372de6"
      },
      "source": [
        "# make results folder if does not exist yet\n",
        "if not os.path.isdir(\"results\"):\n",
        "    os.mkdir(\"results\")\n",
        "# train the model\n",
        "model.fit(ds, steps_per_epoch=(len(encoded_text) - sequence_length) // BATCH_SIZE, epochs=EPOCHS)\n",
        "# save the model\n",
        "model.save(f\"results/{BASENAME}-{sequence_length}.h5\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "1209/1209 [==============================] - 45s 37ms/step - loss: 2.0633\n",
            "Epoch 2/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.4949\n",
            "Epoch 3/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.3776\n",
            "Epoch 4/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.3174\n",
            "Epoch 5/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.2779\n",
            "Epoch 6/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.2506\n",
            "Epoch 7/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.2269\n",
            "Epoch 8/30\n",
            "1209/1209 [==============================] - 43s 36ms/step - loss: 1.2118\n",
            "Epoch 9/30\n",
            "1209/1209 [==============================] - 43s 36ms/step - loss: 1.1912\n",
            "Epoch 10/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1772\n",
            "Epoch 11/30\n",
            "1209/1209 [==============================] - 45s 37ms/step - loss: 1.1664\n",
            "Epoch 12/30\n",
            "1209/1209 [==============================] - 45s 37ms/step - loss: 1.1578\n",
            "Epoch 13/30\n",
            "1209/1209 [==============================] - 45s 37ms/step - loss: 1.1505\n",
            "Epoch 14/30\n",
            "1209/1209 [==============================] - 44s 37ms/step - loss: 1.1410\n",
            "Epoch 15/30\n",
            "1209/1209 [==============================] - 44s 37ms/step - loss: 1.1479\n",
            "Epoch 16/30\n",
            "1209/1209 [==============================] - 44s 37ms/step - loss: 1.1427\n",
            "Epoch 17/30\n",
            "1209/1209 [==============================] - 44s 37ms/step - loss: 1.1275\n",
            "Epoch 18/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1407\n",
            "Epoch 19/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1277\n",
            "Epoch 20/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1440\n",
            "Epoch 21/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1298\n",
            "Epoch 22/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1389\n",
            "Epoch 23/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.3772\n",
            "Epoch 24/30\n",
            "1209/1209 [==============================] - 44s 37ms/step - loss: 1.3281\n",
            "Epoch 25/30\n",
            "1209/1209 [==============================] - 44s 37ms/step - loss: 1.1693\n",
            "Epoch 26/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1839\n",
            "Epoch 27/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1708\n",
            "Epoch 28/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.1892\n",
            "Epoch 29/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.2487\n",
            "Epoch 30/30\n",
            "1209/1209 [==============================] - 44s 36ms/step - loss: 1.6748\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ejB7G2hjUbV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(f'/content/drive/My Drive/{BASENAME}-{sequence_length}.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfTolzfutCqg",
        "colab_type": "text"
      },
      "source": [
        "# **Generating New Text**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqCA_lUDhOpT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import tqdm\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM, Dropout, Activation\n",
        "import os\n",
        "\n",
        "sequence_length = 100\n",
        "# dataset file path\n",
        "FILE_PATH = \"data/wonderland.txt\"\n",
        "# FILE_PATH = \"data/python_code.py\"\n",
        "BASENAME = os.path.basename(FILE_PATH)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5r9NdFDtIaJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed = \"chapter xiii\"\n",
        "# load vocab dictionaries\n",
        "char2int = pickle.load(open(f\"{BASENAME}-char2int.pickle\", \"rb\"))\n",
        "int2char = pickle.load(open(f\"{BASENAME}-int2char.pickle\", \"rb\"))\n",
        "vocab_size = len(char2int)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wg05mQJatPgV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# building the model\n",
        "model = Sequential([\n",
        "    LSTM(256, input_shape=(sequence_length, vocab_size), return_sequences=True),\n",
        "    Dropout(0.3),\n",
        "    LSTM(256),\n",
        "    Dense(vocab_size, activation=\"softmax\"),\n",
        "])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WwJTHX9JtUyN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the optimal weights\n",
        "model.load_weights(f\"results/{BASENAME}-{sequence_length}.h5\")"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIxsfYtatWsd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "2f9f66ea-91c5-4e7e-cb25-26f70a601ec5"
      },
      "source": [
        "s = seed\n",
        "n_chars = 400\n",
        "# generate 400 characters\n",
        "generated = \"\"\n",
        "for i in tqdm.tqdm(range(n_chars), \"Generating text\"):\n",
        "    # make the input sequence\n",
        "    X = np.zeros((1, sequence_length, vocab_size))\n",
        "    for t, char in enumerate(seed):\n",
        "        X[0, (sequence_length - len(seed)) + t, char2int[char]] = 1\n",
        "    # predict the next character\n",
        "    predicted = model.predict(X, verbose=0)[0]\n",
        "    # converting the vector to an integer\n",
        "    next_index = np.argmax(predicted)\n",
        "    # converting the integer to a character\n",
        "    next_char = int2char[next_index]\n",
        "    # add the character to results\n",
        "    generated += next_char\n",
        "    # shift seed and the predicted character\n",
        "    seed = seed[1:] + next_char\n",
        "\n",
        "print(\"Seed:\", s)\n",
        "print(\"Generated text:\")\n",
        "print(generated)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Generating text: 100%|██████████| 400/400 [00:09<00:00, 41.02it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Seed: chapter xiii\n",
            "Generated text:\n",
            "bbing and the mouse time and alice as she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and the stock and she spoket and\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9CQ0DvGttag1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}